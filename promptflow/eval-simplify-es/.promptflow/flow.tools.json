{
  "package": {},
  "code": {
    "line_process.py": {
      "type": "python",
      "inputs": {
        "groundtruth": {
          "type": [
            "string"
          ]
        },
        "prediction": {
          "type": [
            "string"
          ]
        }
      },
      "description": "This tool processes the prediction of a single line and returns the processed result.\n\n:param groundtruth: the groundtruth of a single line.\n:param prediction: the prediction of a single line.",
      "source": "line_process.py",
      "function": "line_process"
    },
    "aggregate.py": {
      "type": "python",
      "inputs": {
        "scores": {
          "type": [
            "object"
          ]
        }
      },
      "description": "This tool aggregates the processed result of all lines and calculate the accuracy. Then log metric for the accuracy.\n\n:param scores: List of the output of a readability scorer node.",
      "source": "aggregate.py",
      "function": "aggregate"
    },
    "calculate_score.py": {
      "type": "python",
      "inputs": {
        "text": {
          "type": [
            "string"
          ]
        }
      },
      "source": "calculate_score.py",
      "function": "calculate_score"
    },
    "cefr_level.py": {
      "type": "python",
      "inputs": {
        "score": {
          "type": [
            "double"
          ]
        }
      },
      "description": "Get CEFR level from understandability score.\n\nWe calculated these ranges by scoring various text samples where we had an approximate idea of their CEFR level. Again these ranges are not perfect, but give a good indication of the CEFR level.",
      "source": "cefr_level.py",
      "function": "get_cefr_level"
    }
  }
}